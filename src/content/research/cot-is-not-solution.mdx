import Cite from "../../components/Cite";
import References from "../../components/References";

# Large Language Models Do Not Truly Reason

## Introduction
Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation. Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation.Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation. Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation.Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation. Large language models demonstrate impressive surface-level reasoning,
yet fail under controlled evaluation<Cite id="chollet2019" />.
$$
Inline math:
$$
The transformer computes attention as $QK^T / \sqrt{d_k}$.
$$
Block equations:
$$
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

## Pattern Matching vs Reasoning
We analyze failure cases where statistical correlation mimics inference.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning<Cite id="marcus2020" />.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning<Cite id="wei2022" />.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.

## Benchmark Illusions
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.
Many benchmarks reward shortcuts rather than genuine reasoning.

## Conclusion
Scaling alone is insufficient for reliable reasoning systems.
<References
  items={{
    chollet2019: "Chollet, F., *On the Measure of Intelligence*, arXiv, 2019.",
    marcus2020: "Marcus, G., *The Next Decade in AI*, MIT Press, 2020.",
    wei2022: "Wei et al., *Chain-of-Thought Prompting*, NeurIPS, 2022."
  }}
/>